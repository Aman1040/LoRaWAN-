# -*- coding: utf-8 -*-
"""Feature_selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113u96lB_2G0lbGMgN8gv2FLyt4NNzU1T
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For feature selection
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel

# For statistical analysis
from scipy import stats

df=pd.read_csv('file1.csv')
df



print(df.describe())

# df['time'] = pd.to_datetime(df['time']).astype('int64') // 10**9

# print(df['time'])

numeric_cols = df.select_dtypes(include='number').columns
print(numeric_cols)

selected_cols = numeric_cols.unique()
numeric_df = df[selected_cols]
numeric_df

# Histograms for numerical features
for col in numeric_df:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.show()

corr_matrix = numeric_df.corr()

# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split




# Specify your features and target
features = ['frequency', 'spreading_factor', 'bandwidth', 'rssi', 'snr', 'size', 'mtype', 'fcnt', 'fport']
target = 'crc_status'

X = df[features]
y = df[target]

# Handle categorical variables
X = pd.get_dummies(X, columns=['mtype'], drop_first=True)

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and fit the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Get feature importances
importances = model.feature_importances_
feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})
feature_importances = feature_importances.sort_values(by='importance', ascending=False)

# Select top N features
top_n = 3
best_features = feature_importances.head(top_n)['feature'].tolist()

print("Best features selected:", best_features)

# # Final DataFrame with selected features and target
# X_final = numeric_df[best_features + [target]]

# Final DataFrame with selected features and target
X_final = numeric_df[best_features + [target]]
X_final

